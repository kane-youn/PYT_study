{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyOlde6lyWRqOiIsQaqx/+4g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kane-youn/PYT_study/blob/main/TS_250822.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBOsav1U4f2W"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 0) Imports & Seed\n",
        "# =========================\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# =========================\n",
        "# 1) Synthetic time series\n",
        "# =========================\n",
        "T = 1200\n",
        "t = np.arange(T)\n",
        "series_raw = (\n",
        "    np.sin(2*np.pi*t/50)       # 주기 50\n",
        "    + 0.5*np.sin(2*np.pi*t/12) # 주기 12\n",
        "    + 0.01*t                   # 완만한 추세\n",
        ")\n",
        "series_raw += 0.25*np.random.randn(T)  # 잡음 조금 더 강하게 (극값 학습 확인용)\n",
        "\n",
        "# 전역 표준화\n",
        "series = (series_raw - series_raw.mean()) / (series_raw.std() + 1e-8)\n",
        "\n",
        "# =========================\n",
        "# 2) Windowing (multi-step)\n",
        "# =========================\n",
        "def make_windows(data, window_size=96, horizon=24):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window_size - horizon + 1):\n",
        "        X.append(data[i:i+window_size])\n",
        "        y.append(data[i+window_size:i+window_size+horizon])\n",
        "    X = np.array(X)[..., np.newaxis]  # (B, W, 1)\n",
        "    y = np.array(y)                   # (B, H)\n",
        "    return X, y\n",
        "\n",
        "window_size = 96\n",
        "horizon     = 24\n",
        "X, y = make_windows(series, window_size, horizon)\n",
        "\n",
        "# train/val/test = 60/20/20\n",
        "n = len(X)\n",
        "n_train = int(n*0.6)\n",
        "n_val   = int(n*0.2)\n",
        "X_train, y_train = X[:n_train], y[:n_train]\n",
        "X_val,   y_val   = X[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
        "X_test,  y_test  = X[n_train+n_val:], y[n_train+n_val:]\n",
        "\n",
        "# =========================\n",
        "# 3) Positional Encoding\n",
        "# =========================\n",
        "def positional_encoding(length, d_model):\n",
        "    pos = np.arange(length)[:, np.newaxis].astype(np.float32)      # (W,1)\n",
        "    i   = np.arange(d_model)[np.newaxis, :].astype(np.float32)     # (1,D)\n",
        "    angle_rates = 1.0 / np.power(10000.0, (2*(i//2))/d_model)      # (1,D)\n",
        "    angles = pos * angle_rates                                     # (W,D)\n",
        "    pe = np.zeros((length, d_model), dtype=np.float32)\n",
        "    pe[:, 0::2] = np.sin(angles[:, 0::2])\n",
        "    pe[:, 1::2] = np.cos(angles[:, 1::2])\n",
        "    return tf.constant(pe)  # (W,D)\n",
        "\n",
        "# =========================\n",
        "# 4) Transformer Encoder (Encoder-only)\n",
        "# =========================\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_model//num_heads, dropout=dropout\n",
        "        )\n",
        "        self.dropout1 = layers.Dropout(dropout)\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.ffn = keras.Sequential([\n",
        "            layers.Dense(dff, activation=\"relu\"),\n",
        "            layers.Dense(d_model),\n",
        "        ])\n",
        "        self.dropout2 = layers.Dropout(dropout)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        attn_output = self.mha(query=x, value=x, key=x, attention_mask=mask, training=training)\n",
        "        out1 = self.norm1(x + self.dropout1(attn_output, training=training))\n",
        "        ffn_output = self.ffn(out1)\n",
        "        out2 = self.norm2(out1 + self.dropout2(ffn_output, training=training))\n",
        "        return out2\n",
        "\n",
        "# =========================\n",
        "# 5) Quantile Loss (pinball) & Non-crossing head\n",
        "# =========================\n",
        "def pinball_loss(y_true, y_pred, q):\n",
        "    # y_true, y_pred: (B, H)\n",
        "    e = y_true - y_pred\n",
        "    return tf.reduce_mean(tf.maximum(q*e, (q-1.0)*e))\n",
        "\n",
        "class MultiQuantileHead(layers.Layer):\n",
        "    \"\"\"\n",
        "    q10 <= q50 <= q90 를 강제:\n",
        "    q50 = base\n",
        "    q10 = base - softplus(delta_lo)\n",
        "    q90 = base + softplus(delta_hi)\n",
        "    \"\"\"\n",
        "    def __init__(self, horizon):\n",
        "        super().__init__()\n",
        "        self.base = layers.Dense(horizon, activation=\"linear\")      # q50\n",
        "        self.delta_lo = layers.Dense(horizon, activation=\"linear\")  # for q10\n",
        "        self.delta_hi = layers.Dense(horizon, activation=\"linear\")  # for q90\n",
        "\n",
        "    def call(self, x):\n",
        "        base = self.base(x)                    # (B,H)\n",
        "        lo   = base - tf.nn.softplus(self.delta_lo(x))\n",
        "        hi   = base + tf.nn.softplus(self.delta_hi(x))\n",
        "        return lo, base, hi                    # q10, q50, q90\n",
        "\n",
        "def quantile_model(window_size, d_model=128, num_heads=8, dff=256,\n",
        "                   num_layers=3, dropout=0.1, horizon=24):\n",
        "    inp = layers.Input(shape=(window_size, 1))   # (B,W,1)\n",
        "    x = layers.Dense(d_model)(inp)\n",
        "    x = x + positional_encoding(window_size, d_model)\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        x = TransformerEncoder(d_model, num_heads, dff, dropout)(x)\n",
        "\n",
        "    x = x[:, -1, :]                               # last token\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    head = MultiQuantileHead(horizon)\n",
        "    q10, q50, q90 = head(x)                       # (B,H) each\n",
        "    model = keras.Model(inp, [q10, q50, q90])\n",
        "    return model\n",
        "\n",
        "# 커스텀 훈련 루프 대신, keras loss 3개로 합산\n",
        "q_list = [0.1, 0.5, 0.9]\n",
        "def make_losses():\n",
        "    def loss_q10(y_true, y_pred): return pinball_loss(y_true, y_pred, q_list[0])\n",
        "    def loss_q50(y_true, y_pred): return pinball_loss(y_true, y_pred, q_list[1])\n",
        "    def loss_q90(y_true, y_pred): return pinball_loss(y_true, y_pred, q_list[2])\n",
        "    return loss_q10, loss_q50, loss_q90\n",
        "\n",
        "# =========================\n",
        "# 6) Build & Train\n",
        "# =========================\n",
        "model = quantile_model(window_size, d_model=128, num_heads=8, dff=256,\n",
        "                       num_layers=3, dropout=0.1, horizon=horizon)\n",
        "losses = make_losses()\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(5e-4),\n",
        "    loss=list(losses),              # [loss_q10, loss_q50, loss_q90]\n",
        "    loss_weights=[1.0, 2.0, 1.0]    # 중앙(0.5)에 가중치를 더 주어 안정화\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "es = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True, monitor=\"val_loss\")\n",
        "hist = model.fit(\n",
        "    X_train, [y_train, y_train, y_train],    # 세 개의 타깃에 동일한 y\n",
        "    validation_data=(X_val, [y_val, y_val, y_val]),\n",
        "    epochs=300, batch_size=64, callbacks=[es], verbose=1\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 7) Predict\n",
        "# =========================\n",
        "q10_pred, q50_pred, q90_pred = model.predict(X_test)   # 각 (Ntest, H)\n",
        "y_true = y_test                                        # (Ntest, H)\n",
        "\n",
        "# =========================\n",
        "# 8) Metrics & Coverage\n",
        "# =========================\n",
        "# 중앙선 기준 점오차\n",
        "mae_med  = np.mean(np.abs(y_true - q50_pred))\n",
        "rmse_med = np.sqrt(np.mean((y_true - q50_pred)**2))\n",
        "print(f\"Median (q50) Overall MAE : {mae_med:.4f}\")\n",
        "print(f\"Median (q50) Overall RMSE: {rmse_med:.4f}\")\n",
        "\n",
        "# 스텝별 MAE\n",
        "mae_per_h = np.mean(np.abs(y_true - q50_pred), axis=0)\n",
        "print(\"MAE per step:\", np.round(mae_per_h, 4))\n",
        "\n",
        "# 10~90% 밴드 커버리지 (이론상 ~0.8 근처가 이상적)\n",
        "coverage_10_90 = np.mean((y_true >= q10_pred) & (y_true <= q90_pred))\n",
        "print(f\"Central 80% band coverage: {coverage_10_90:.3f}\")\n",
        "\n",
        "# =========================\n",
        "# 9) Plots\n",
        "# =========================\n",
        "# (a) 한 윈도우의 H-step 경로\n",
        "idx = min(50, len(X_test)-1)\n",
        "xs = np.arange(horizon)\n",
        "plt.figure(figsize=(9,4))\n",
        "plt.plot(xs, y_true[idx], label=\"Actual (next H)\")\n",
        "plt.plot(xs, q50_pred[idx], label=\"q50 (median)\")\n",
        "plt.fill_between(xs, q10_pred[idx], q90_pred[idx], alpha=0.2, label=\"80% band (q10~q90)\")\n",
        "plt.title(f\"Multi-step Quantile Forecast (idx={idx})\")\n",
        "plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "# (b) 겹치지 않는 롤링 백테스트\n",
        "sel = np.arange(0, len(y_true), horizon)\n",
        "true_seq = y_true[sel].reshape(-1)\n",
        "q50_seq  = q50_pred[sel].reshape(-1)\n",
        "q10_seq  = q10_pred[sel].reshape(-1)\n",
        "q90_seq  = q90_pred[sel].reshape(-1)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(true_seq, label=\"Actual\")\n",
        "plt.plot(q50_seq,  label=\"q50\")\n",
        "plt.fill_between(np.arange(len(q50_seq)), q10_seq, q90_seq, alpha=0.2, label=\"80% band\")\n",
        "plt.title(f\"Rolling multi-step backtest (stride = horizon={horizon})\")\n",
        "plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(true_seq, label=\"Actual\")\n",
        "# plt.plot(X, label=\"RAW\")\n",
        "plt.plot(series, label=\"STD\")\n"
      ],
      "metadata": {
        "id": "cNhcSj44BDOY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}